{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the api_key defined in .env file\n",
    "load_dotenv()\n",
    "api_key = os.getenv('api_key')\n",
    "\n",
    "# Specify the model to use\n",
    "model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Agent Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "    \n",
    "class MultiModalAgent:\n",
    "    def __init__(self, system_prompt):\n",
    "        \"\"\"\n",
    "        Initialize the agent with a system prompt that defines its personality/role,\n",
    "        and the desired model.\n",
    "        \"\"\"\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.model = model\n",
    "        # Initialize conversation history with the system prompt.\n",
    "        self.conversation_history = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt}\n",
    "        ]\n",
    "\n",
    "    def send_message(self, text, image_path=None, response_format=None):\n",
    "        \"\"\"\n",
    "        Send a message to the agent and get its reply. The conversation history is automatically updated.\n",
    "        \"\"\"\n",
    "        # Define the message\n",
    "        if image_path is None:\n",
    "            message = {\"role\": \"user\", \"content\": text}\n",
    "        else:\n",
    "            base64_image = encode_image(image_path)\n",
    "            message = {\n",
    "                        \"role\": \"user\", \n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": text,\n",
    "                            },\n",
    "                            {\n",
    "                                \"type\": \"image_url\",\n",
    "                                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"},\n",
    "                            }\n",
    "                        ]\n",
    "                        }\n",
    "\n",
    "        # Append the user's message\n",
    "        self.conversation_history.append(message)\n",
    "        \n",
    "        # Call the Chat Completion API\n",
    "        if response_format is None:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=self.conversation_history,\n",
    "            )\n",
    "        else:\n",
    "            response = self.client.beta.chat.completions.parse(\n",
    "                model=self.model,\n",
    "                messages=self.conversation_history,\n",
    "                response_format=response_format\n",
    "            )\n",
    "        \n",
    "        # Extract the assistant's reply\n",
    "        reply = response.choices[0].message.content.strip()\n",
    "        \n",
    "        # Append the assistant's reply to maintain conversation context\n",
    "        self.conversation_history.append({\"role\": \"assistant\", \"content\": reply})\n",
    "        \n",
    "        return response\n",
    "\n",
    "    def reset_conversation(self):\n",
    "        \"\"\"\n",
    "        Resets the conversation history while retaining the system prompt.\n",
    "        \"\"\"\n",
    "        system_message = self.conversation_history[0]\n",
    "        self.conversation_history = [system_message]\n",
    "\n",
    "    def get_history(self):\n",
    "        \"\"\"\n",
    "        Returns the full conversation history.\n",
    "        \"\"\"\n",
    "        return self.conversation_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an agent with a role\n",
    "agent1 = MultiModalAgent(\"Suppose you are a college student from Hong Kong from now on. Please answer my questions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm a college student from Hong Kong, studying various subjects and navigating campus life. If you have any questions or need assistance, feel free to ask!\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the role understanding\n",
    "agent1.send_message(\"Who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The image features the logo of the 2008 Beijing Olympics. It symbolizes China, specifically Beijing, which hosted the Summer Olympics that year. The design incorporates elements of traditional Chinese art.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the image understanding\n",
    "agent1.send_message(\"What's in this image? Which country does this picture symbolize?\", image_path=\"osfstorage-archive/Pictures/Chinese Pictures/1.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cultural Priming (single agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the response format\n",
    "class Prime_Response(BaseModel):\n",
    "    image_description: str\n",
    "    rating: int\n",
    "    country: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The picture shows a scenic view of the Great Wall of China, with fortifications stretching across green hills under a clear blue sky.\n",
      "9\n",
      "China\n"
     ]
    }
   ],
   "source": [
    "# Generate the response with the certain format\n",
    "prompt = \"How much do you like this picture from 1 (strongly dislike) to 10 (strongly like)? Which country does this picture symbolize?\" # Prompt for the two questions\n",
    "image_path = \"osfstorage-archive/Pictures/Chinese Pictures/2.jpg\"\n",
    "response = agent1.send_message(prompt, image_path=image_path, response_format=Prime_Response)\n",
    "\n",
    "# Check each field of the response\n",
    "print(response.choices[0].message.parsed.image_description)\n",
    "print(response.choices[0].message.parsed.rating)\n",
    "print(response.choices[0].message.parsed.country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to Responses/response1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prime_Response(image_description='The picture shows a scenic view of the Great Wall of China, with fortifications stretching across green hills under a clear blue sky.', rating=9, country='China')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of saving and loading saved reponse\n",
    "def save_to_json(instance: BaseModel, filename=\"data.json\"):\n",
    "    \"\"\" \n",
    "    Save the response to a json file\n",
    "    \"\"\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(instance.model_dump_json(indent=4))  # Convert to JSON and write to file\n",
    "    print(f\"Saved to {filename}\")\n",
    "\n",
    "def load_from_json(model_class, filename=\"response.json\"):\n",
    "    \"\"\"\n",
    "    Load the json file and convert it back to the original format\n",
    "    \"\"\"\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return model_class(**data)\n",
    "\n",
    "save_path = \"Responses/response1.json\"\n",
    "save_to_json(response.choices[0].message.parsed, filename=save_path) # save to a json file\n",
    "reponse = load_from_json(Prime_Response, save_path) # load the \n",
    "reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to Responses/Chinese/Agent1/log1.json\n",
      "Saved to Responses/Chinese/Agent1/log2.json\n"
     ]
    }
   ],
   "source": [
    "# An example of using loop to prime the agent with multiple chinese images and save them into a file\n",
    "for i in range(1, 3):\n",
    "    image_path = f\"osfstorage-archive/Pictures/Chinese Pictures/{i}.jpg\"\n",
    "    log_path = f\"Responses/Chinese/Agent1/log{i}.json\"\n",
    "    response = agent1.send_message(prompt, image_path=image_path, response_format=Prime_Response)\n",
    "    save_to_json(response.choices[0].message.parsed, log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Attribution Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the response format\n",
    "class Attribution_Response(BaseModel):\n",
    "    rating_q1: int\n",
    "    reason_q1: str\n",
    "    rating_q2: int\n",
    "    reason_q2: str\n",
    "    rating_q3: int\n",
    "    reason_q3: str\n",
    "    rating_q4: int\n",
    "    reason_q4: str\n",
    "    rating_q5: int\n",
    "    reason_q5: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"osfstorage-archive/Pictures/fish_internal.png\"\n",
    "# Prompt the agent with the task instruction\n",
    "prompt = ''' \n",
    "Please answer five rating questions regarding the picture according to your 'personal opinion'. The rating scales from 1 to 5.\n",
    "Why one fish is swimming in front of the group? (1 = I’m very confident that it is because the one fish is leading the other fish, 5 = I’m very confident that it is because the one fish is being chased by the other fish)\n",
    "Is this fish on the left an important member of the group of fish on the right? (1 = It is obviously not an important member of the school on the left, 5 = It is obviously an important member of the school on the left)\n",
    "How much is the fish on the left influenced by its own factors? (1 = It is hardly influenced by itself, 5 = It is completely influenced by itself)\n",
    "How much is the fish on the left influenced by the other fish? (1 = It is hardly influenced by the other fish, 5 = It is completely influenced by the other fish)\n",
    "To what extent are the actions of the other fish influenced by the fish on the right? (1 = The actions of the other fish are hardly influenced by the fish on the right, 5 = The actions of the other fish are completely influenced by the fish on the right)\n",
    "'''\n",
    "response = agent1.send_message(prompt, image_path=image_path, response_format=Attribution_Response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
